{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path\n",
    "from os import path\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing.image import load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Dense, UpSampling3D, Conv3D, AveragePooling2D\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from skimage.color import lab2rgb, rgb2lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.63 GiB for an array with shape (2800, 300, 300, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-240-5dcc09c06730>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimages_glob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages_glob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2800\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlab_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages_glob\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"done loading data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 5.63 GiB for an array with shape (2800, 300, 300, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "images_glob = glob.glob('/home/mario/MIU/ML/final-project/image-colorizer-notebook/unlabeled2017_subsample/*.jpg')\n",
    "images_glob = images_glob[:2800]\n",
    "\n",
    "lab_images = np.array([np.array(load_img(img_path)) / 255 for img_path in images_glob])\n",
    "done = \"done loading data\"\n",
    "done\n",
    "lab_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_lab(img):\n",
    "  return (img + [0, 128, 128])/[100, 255, 255]\n",
    "\n",
    "def denormalize_lab(img):\n",
    "  return (img * [100, 255, 255]) - [0, 128, 128]\n",
    "\n",
    "def convert_rgb_to_lab(img):\n",
    "  return normalize_lab(rgb2lab(img))\n",
    "\n",
    "def convert_lab_to_rgb(img):\n",
    "  return lab2rgb(denormalize_lab(img))\n",
    "\n",
    "def extract_grayscalergb_from_lab(image):\n",
    "  bw = np.zeros(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#actually convert to LAB and scale according to L*a*b format values range\n",
    "lab_images = np.array([convert_rgb_to_lab(img) for img in lab_images])\n",
    "\n",
    "print(lab_images.shape)\n",
    "\n",
    "done = 'done converting to grayscale'\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.imshow(lab_images[666])\n",
    "plt.figure(2)\n",
    "plt.imshow(convert_lab_to_rgb(lab_images[666]), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "IMG_WIDTH = 300\n",
    "IMG_HEIGHT = 300\n",
    "# We will predict the a*b layers from the L layer of LAB formatted image\n",
    "inputs = np.array(lab_images[:, :, :, 0]).reshape(len(lab_images), IMG_WIDTH, IMG_HEIGHT, 1)\n",
    "outputs = np.array(lab_images[:, :, :, 1:]).reshape(len(lab_images), IMG_WIDTH, IMG_HEIGHT, 2)\n",
    "\n",
    "# split is 70 * 30 for training. Set to 95 * 5 for actual testing\n",
    "train_X, test_X, train_y, test_y = train_test_split(inputs, outputs, train_size=0.90)\n",
    "\n",
    "test_X, test_y = np.array(test_X), np.array(test_y)\n",
    "\n",
    "done = 'done splitting data'\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resnet = ResNet50(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create working prediction model\n",
    "\n",
    "# TODO: add imagenet layer and freeze\n",
    "# TODO: add CAM by getting Conv2D in the middle, summing them up elementwise and plotting over original input.\n",
    "\n",
    "if not path.exists(\"/home/mario/MIU/ML/final-project/image-colorizer-notebook/saved.model\"):\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(IMG_WIDTH, IMG_HEIGHT, 1)))\n",
    "    model.add(UpSampling3D((1, 1, 3)))\n",
    "    model.add(resnet)\n",
    "    model.layers[-1].trainable = False\n",
    "    model.add(UpSampling2D((4, 4)))\n",
    "    model.add(Conv2D(8, (4, 4), activation='relu', padding='valid', strides=2))\n",
    "    model.add(Conv2D(16, (4, 4), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', padding='same', strides=2))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', strides=1))\n",
    "    model.add(UpSampling2D((2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(UpSampling2D((3, 3)))\n",
    "    model.add(Conv2D(16, (2, 2), activation='relu', padding='same'))\n",
    "    model.add(UpSampling2D((5, 5)))\n",
    "    model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
    "    model.summary()\n",
    "print('done creating layer stack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if path.exists(\"/home/mario/MIU/ML/final-project/image-colorizer-notebook/saved.model\"):\n",
    "  model = keras.models.load_model(\"/home/mario/MIU/ML/final-project/image-colorizer-notebook/saved.model\")\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['accuracy'])\n",
    "print('done compiling...')\n",
    "model.fit(x=train_X, y=train_y, batch_size=50, epochs=100, verbose=2)\n",
    "model.save(\"/home/mario/MIU/ML/final-project/image-colorizer-notebook/saved.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Warning: takes long to load\n",
    "model.evaluate(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_test_idx = 997\n",
    "\n",
    "test_pred = model.predict(np.array([inputs[visual_test_idx]]))\n",
    "\n",
    "predicted_LAB = np.zeros((IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "predicted_LAB[:, :, 0] = inputs[visual_test_idx][:, :, 0]\n",
    "predicted_LAB[:, :, 1:] = test_pred[0]\n",
    "predicted_RGB = convert_lab_to_rgb(predicted_LAB)\n",
    "\n",
    "plt.figure(4)\n",
    "plt.imshow(predicted_RGB)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

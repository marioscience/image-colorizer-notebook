{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing.image import load_img\n",
    "import lodgepole.image_tools as lit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Dense\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from skimage.color import lab2rgb, rgb2lab\n",
    "\n",
    "images_glob = glob.glob('/home/mario/Downloads/image-datasets/unlabeled2017_subsample/*.jpg')\n",
    "images_glob = images_glob[:1000]\n",
    "\n",
    "images = np.array([np.array(load_img(img_path)) / 255 for img_path in images_glob])\n",
    "done = \"done loading data\"\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def normalize_lab(img):\n",
    "  return (img + [0, 128, 128])/[100, 255, 255]\n",
    "\n",
    "def denormalize_lab(img):\n",
    "  return (img * [100, 255, 255]) - [0, 128, 128]\n",
    "\n",
    "def convert_rgb_to_lab(img):\n",
    "  return normalize_lab(rgb2lab(img))\n",
    "\n",
    "def convert_lab_to_rgb(img):\n",
    "  return lab2rgb(denormalize_lab(img))\n",
    "\n",
    "def extract_grayscalergb_from_lab(image):\n",
    "  bw = np.zeros(image.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#actually convert to LAB and scale according to L*a*b format values range\n",
    "lab_images = np.array([convert_rgb_to_lab(img) for img in images])\n",
    "\n",
    "plt.figure(1)\n",
    "plt.imshow(images[101], cmap='gray')\n",
    "plt.figure(2)\n",
    "plt.imshow(lab_images[101])\n",
    "plt.figure(3)\n",
    "#\n",
    "plt.imshow(convert_lab_to_rgb(lab_images[101]), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(images.shape)\n",
    "print(lab_images.shape)\n",
    "\n",
    "done = 'done converting to grayscale'\n",
    "done"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "IMG_WIDTH = 300\n",
    "IMG_HEIGHT = 300\n",
    "# We will predict the a*b layers from the L layer of LAB formatted image\n",
    "inputs = np.array(lab_images[:, :, :, 0]).reshape(len(lab_images), IMG_WIDTH, IMG_HEIGHT, 1)\n",
    "outputs = np.array(lab_images[:, :, :, 1:]).reshape(len(lab_images), IMG_WIDTH, IMG_HEIGHT, 2)\n",
    "\n",
    "# split is 70 * 30 for training. Set to 95 * 5 for actual testing\n",
    "train_X, test_X, train_y, test_y = train_test_split(inputs, outputs, train_size=0.70)\n",
    "\n",
    "test_X, test_y = np.array(test_X), np.array(test_y)\n",
    "\n",
    "done = 'done splitting data'\n",
    "done"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create working prediction model\n",
    "\n",
    "# TODO: add imagenet layer and freeze\n",
    "# TODO: add CAM by getting Conv2D in the middle, summing them up elementwise and plotting over original input.\n",
    "model = ResNet50(weights='imagenet')\n",
    "model.add(InputLayer(input_shape=(IMG_WIDTH, IMG_HEIGHT, 1)))\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', strides=3))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((3, 3)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
    "print('done creating layer stack')\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['accuracy'])\n",
    "print('done compiling...')\n",
    "model.fit(x=train_X, y=train_y, batch_size=1, epochs=5, verbose=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.evaluate(test_X, test_y)\n",
    "\n",
    "visual_test_idx = 35\n",
    "\n",
    "test_pred = model.predict(np.array([inputs[visual_test_idx]]))\n",
    "\n",
    "predicted_LAB = np.zeros((IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "predicted_LAB[:, :, 0] = inputs[visual_test_idx][:, :, 0]\n",
    "predicted_LAB[:, :, 1:] = test_pred[0]\n",
    "predicted_RGB = convert_lab_to_rgb(predicted_LAB)\n",
    "\n",
    "plt.figure(4)\n",
    "plt.imshow(predicted_RGB)\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}